{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cd8da0-3d3c-434d-8789-c459cfa89779",
   "metadata": {},
   "source": [
    "## KoBART 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d261de0e-4255-49f9-bba4-43596436ebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6dfa64-77d7-47d3-90fd-e30a69499b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ssafy\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssafy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e0cbff7-43a6-4631-9f96-e9cc999c4992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5a1b86-312b-4ff9-a899-475a0c81d7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ssafy\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssafy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssafy\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed65af8-46a0-449f-95ba-80ecdf6d7507",
   "metadata": {},
   "source": [
    "## 질문과 답변 구분:\n",
    "\n",
    "- question과 answer 변수를 따로 정의하고, 입력 텍스트에 \"질문: \" 및 \"답변: \"과 같은 명확한 라벨을 추가\n",
    "- 이를 통해 모델이 텍스트의 구조를 이해하고 질문과 답변의 관계를 파악하여 더 나은 요약을 생성\n",
    "\n",
    "#### 입력 구성:\n",
    "\n",
    "- 모델에 전달할 텍스트를 질문: {질문 내용} 답변: {답변 내용} 형식으로 구성하여 입력\n",
    "#### 요약 생성:\n",
    "\n",
    "- 토큰화된 입력 텍스트를 사용하여 요약을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3b7539-93a6-4219-9a3d-3bb208647592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# KoBART 모델과 토크나이저 로드\n",
    "model_name = \"gogamza/kobart-summarization\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134ee8a3-f366-480a-9f5d-a8c5765f26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 요약: 빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. 계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# KoBART 모델과 토크나이저 로드\n",
    "model_name = \"gogamza/kobart-summarization\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 질문과 답변 설정\n",
    "question = \"포스코 DX에 입사를 해야하는 이유와 지원분야에 관심을 가지게 된 배경을 설명해 주세요.\"\n",
    "answer = \"\"\"\n",
    "[리딩 철강 브랜드의 변화]\n",
    "국내 최초의 등대공장, 물류 fulfillment 등의 이슈를 접하며, POSCO에 대한 관심을 가졌습니다. 그 중 빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. 계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과 물류관리 자동화 방식은 리딩 철강 브랜드로 만들기에 충분했다고 생각합니다. 또한 글로벌 기업의 기술력이 아닌 사내 고유의 인프라를 활용해 신기술을 적용했기 때문에 확장성과 안정성을 동시에 갖출 수 있었습니다.\n",
    "[도전정신을 바탕으로 성장하는 인재]\n",
    "이러한 도전정신이 POSCO DX에 입사하고자 하는 강력한 지원 동기가 되었습니다. 원예과학과를 본 전공으로 선택하면서 연구직을 희망하였습니다. 그중 스마트 팜의 프로그래밍에 관심을 갖고 복수전공으로 컴퓨터 전공을 선택하게 되었습니다. 처음 겪는 과정과 주변의 도움 없이 시작해야 했기 때문에 난관이 많았습니다. 이를 해결하기 위해 학습할 수 있는 다양한 방식을 채택했습니다. 먼저 Open AI에 대한 기술을 접하고 이를 배울 필요가 있다고 생각해 빅데이터와 인공지능 수업을 수강했고, 추가로 BDA라고 하는 데이터 분석 스터디를 수료했습니다. 또한 AI를 활용한 프로젝트에 참여해 공식 문서와 논문을 탐색하며, 필요한 모델을 구현한 경험이 있습니다.\n",
    "[Move in Silence]\n",
    "이런 경험을 바탕으로 입사 후 PosFrame의 확대와 다른 공장들의 자동화 시스템 구축에 일조하고자 합니다. 문제를 해결하는 다양한 접근방식과 새로운 기술에 대한 도전정신을 발휘해 발생할 수 있는 변수들에 대응할 수 있습니다. Git, Jira, Notion 등 기본적인 협력 툴에 대한 이해와 디버깅 과정에서 겪은 비효율적인 구조 개선 방법을 직접 현장에서 적용하고 싶습니다. 사람이 실수하더라도 다치지 않고, 24시간 멈추지 않는 공장처럼 소리 없이 움직이는 개발자가 되고자 POSCO DX에 지원합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 질문과 답변을 결합하여 입력 텍스트 구성\n",
    "input_text = f\"{question} {answer}\"\n",
    "\n",
    "# 입력 텍스트 토큰화\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "\n",
    "# 요약 생성\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=50,        # 요약의 최대 길이\n",
    "    min_length=10,        # 요약의 최소 길이\n",
    "    length_penalty=2.0,   # 길이 페널티 설정\n",
    "    num_beams=4,          # 빔 탐색의 크기\n",
    "    no_repeat_ngram_size=3,  # 반복 방지\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 생성된 요약 텍스트 디코딩\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"생성된 요약:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf387b-df23-4fe9-a975-1b32d5fcd089",
   "metadata": {},
   "source": [
    "### 키워드를 직접 지정하여 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0be7357-524e-4f9d-9160-1d3d1657d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 답변: 그 중 빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. 계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과 물류관리 자동화 방식은 리딩 철강 브랜드로 만들기에 충분했다고 생각합니다. 이러한 도전정신이 POSCO DX에 입사하고자 하는 강력한 지원 동기가 되었습니다.\n",
      "생성된 제목: 빠르게 디지털 전환을 디지털 전환을 성공시켜 smart\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# KoBART 모델과 토크나이저 로드\n",
    "model_name = \"gogamza/kobart-summarization\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 질문과 답변 원문\n",
    "question = \"포스코 DX에 입사하게 된 이유와 관심을 가지게 된 배경을 간단히 설명해 주세요.\"\n",
    "answer = \"\"\"\n",
    "[리딩 철강 브랜드의 변화]\n",
    "국내 최초의 등대공장, 물류 fulfillment 등의 이슈를 접하며, POSCO에 대한 관심을 가졌습니다. 그 중 빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. 계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과 물류관리 자동화 방식은 리딩 철강 브랜드로 만들기에 충분했다고 생각합니다. 또한 글로벌 기업의 기술력이 아닌 사내 고유의 인프라를 활용해 신기술을 적용했기 때문에 확장성과 안정성을 동시에 갖출 수 있었습니다.\n",
    "[도전정신을 바탕으로 성장하는 인재]\n",
    "이러한 도전정신이 POSCO DX에 입사하고자 하는 강력한 지원 동기가 되었습니다. 원예과학과를 본 전공으로 선택하면서 연구직을 희망하였습니다. 그중 스마트 팜의 프로그래밍에 관심을 갖고 복수전공으로 컴퓨터 전공을 선택하게 되었습니다. 처음 겪는 과정과 주변의 도움 없이 시작해야 했기 때문에 난관이 많았습니다. 이를 해결하기 위해 학습할 수 있는 다양한 방식을 채택했습니다. 먼저 Open AI에 대한 기술을 접하고 이를 배울 필요가 있다고 생각해 빅데이터와 인공지능 수업을 수강했고, 추가로 BDA라고 하는 데이터 분석 스터디를 수료했습니다. 또한 AI를 활용한 프로젝트에 참여해 공식 문서와 논문을 탐색하며, 필요한 모델을 구현한 경험이 있습니다.\n",
    "[Move in Silence]\n",
    "이런 경험을 바탕으로 입사 후 PosFrame의 확대와 다른 공장들의 자동화 시스템 구축에 일조하고자 합니다. 문제를 해결하는 다양한 접근방식과 새로운 기술에 대한 도전정신을 발휘해 발생할 수 있는 변수들에 대응할 수 있습니다. Git, Jira, Notion 등 기본적인 협력 툴에 대한 이해와 디버깅 과정에서 겪은 비효율적인 구조 개선 방법을 직접 현장에서 적용하고 싶습니다. 사람이 실수하더라도 다치지 않고, 24시간 멈추지 않는 공장처럼 소리 없이 움직이는 개발자가 되고자 POSCO DX에 지원합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 전처리 함수 개선\n",
    "def preprocess_text(text):\n",
    "    paragraphs = re.split(r'\\[.*?\\]', text)\n",
    "    keywords = [\"디지털 전환\", \"자동화\", \"도전정신\", \"smart-factory\", \"PosFrame\"]\n",
    "    processed_text = []\n",
    "\n",
    "    for para in paragraphs:\n",
    "        sentences = para.split('.')\n",
    "        for sentence in sentences:\n",
    "            if any(keyword in sentence for keyword in keywords):\n",
    "                processed_text.append(sentence.strip() + '.')  # 각 문장의 끝에 마침표 추가\n",
    "\n",
    "    return \" \".join(processed_text[:3])  # 첫 3개의 핵심 문장만 사용\n",
    "\n",
    "# 전처리된 답변 생성\n",
    "processed_answer = preprocess_text(answer)\n",
    "print(\"전처리된 답변:\", processed_answer)\n",
    "\n",
    "# 질문과 전처리된 답변 결합\n",
    "input_text = f\"{question} {processed_answer}\"\n",
    "\n",
    "# 토큰화 및 요약 생성 (간결한 제목 설정)\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=12,       # 제목의 최대 길이\n",
    "    min_length=3,        # 제목의 최소 길이\n",
    "    num_beams=5,         # 빔 탐색을 늘려서 더 나은 요약 도출\n",
    "    no_repeat_ngram_size=3,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 생성된 제목 요약\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"생성된 제목:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6041600a-0b83-40bb-9bc1-e88d5a82af50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 제목:  빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# KoBART 모델과 토크나이저 로드\n",
    "model_name = \"gogamza/kobart-summarization\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 질문과 전처리된 답변 설정\n",
    "question = \"POSCO DX에 지원하게 된 이유를 주제어 형태로 요약해 주세요.\"\n",
    "answer = \"\"\"\n",
    "국내 최초의 등대공장, 물류 fulfillment 등의 이슈를 접하며, POSCO에 대한 관심을 가졌습니다. \n",
    "빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. \n",
    "계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과 물류관리 자동화 방식은 리딩 철강 브랜드로 만들기에 충분했다고 생각합니다. \n",
    "또한 글로벌 기업의 기술력이 아닌 사내 고유의 인프라를 활용해 신기술을 적용했기 때문에 확장성과 안정성을 동시에 갖출 수 있었습니다.\n",
    "\"\"\"\n",
    "\n",
    "# 질문과 전처리된 답변 결합\n",
    "input_text = f\"{question} {answer}\"\n",
    "\n",
    "# 토큰화 및 요약 생성\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=1000,  # 제목 길이 제한\n",
    "    min_length=5,\n",
    "    num_beams=6,\n",
    "    no_repeat_ngram_size=4,  # 반복 방지 강화\n",
    "    length_penalty=2.0,      # 길이 페널티 조정\n",
    "    temperature=0.7,         # 샘플링의 다양성 조정\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 생성된 제목 요약\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"생성된 제목:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39247b22-fddb-48ac-9726-fc7748b531a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050604c-8f34-4618-ada5-53bb1c25bccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331061dd-0f50-49dc-834c-66ccabbe694a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc2b90da-6493-4bec-880c-a6ceac236638",
   "metadata": {},
   "source": [
    "# 생각보다 괜찮은 파라미팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af20df39-7200-4179-8114-d9e06ec96cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한줄 요약 (개조식):  • 이이에 대한 관심을 가졌습니다. 그 중 빠르게 디지털 전환을 빠르게 디지털 전환을 성공시켜\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# KoBART 모델과 전용 토크나이저 로드\n",
    "model_name = \"gogamza/kobart-base-v2\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 요약할 텍스트\n",
    "text = \"\"\"\n",
    "[리딩 철강 브랜드의 변화]\n",
    "국내 최초의 등대공장, 물류 fulfillment 등의 이슈를 접하며, POSCO에 대한 관심을 가졌습니다. 그 중 빠르게 디지털 전환을 성공시켜 smart-factory를 구축시킬 수 있었던 배경인 POSCO DX에 알게 되었습니다. 계획, 제선, 제강, 연주, 압연, 도금으로 이루어진 생산방식과 물류관리 자동화 방식은 리딩 철강 브랜드로 만들기에 충분했다고 생각합니다. 또한 글로벌 기업의 기술력이 아닌 사내 고유의 인프라를 활용해 신기술을 적용했기 때문에 확장성과 안정성을 동시에 갖출 수 있었습니다.\n",
    "\"\"\"\n",
    "\n",
    "# 텍스트를 토큰화하고 텐서로 변환\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=20,   # 더 짧은 요약 문장 길이 설정\n",
    "    min_length=5,\n",
    "    num_beams=5,\n",
    "    length_penalty=2.0,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 생성된 요약문 디코딩\n",
    "headline = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"한줄 요약 (개조식):\", \" •\", headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daab1f61-7a61-4e1e-bfbe-08803b4ebd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한줄 요약 (개조식):  • POSCO DX와 철강산업의 디지털 혁신을 위한 도전\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# KoBERT 모델과 토크나이저 로드\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 질문과 답변 설정\n",
    "text =\"\"\"\n",
    "[ 맞춤형 디지털 혁신으로 고객 경험을 재정의하다 ]\n",
    "\n",
    "저는 서비스를 기획할 때, 고객에게 필요한 서비스 제공을 최우선으로 생각합니다. 고객이 필요성을 느끼지 못하는 서비스는 본래의 목적을 잃었다고 생각하기 때문입니다.\n",
    "\n",
    "하나은행은 ‘고객 맞춤형’ 가치를 중심으로 다양한 디지털 서비스를 제공해 왔습니다. 예를 들어, 초개인화 마케팅 플랫폼과 비대면 실명확인 서비스는 고객의 니즈에 맞춘 대표적인 디지털 서비스 사례입니다. 이를 통해 하나은행은 고객이 은행 업무를 더 편리하게 처리할 수 있는 환경을 구축하며, 고객 경험을 재정의하였습니다.\n",
    "\n",
    "이러한 하나은행의 고객 중심적 디지털 혁신에 깊이 공감하여, 디지털/ICT 직무에서 고객 중심의 서비스를 제공하고자 지원하게 되었습니다.\n",
    "\n",
    "저는 이전에 삼성 청년 SW 아카데미에서 제공하는 교육용 금융 API를 활용해 ‘아티스트 펀딩 서비스’를 개발하며 외부 채널과 내부 시스템을 효과적으로 연동하였습니다. 또한, 두 개의 부트캠프에서 프론트엔드와 백엔드 개발을 모두 경험하며, 프로젝트에서 세 차례의 수상을 하였습니다.\n",
    "\n",
    "이러한 경험을 바탕으로 하나은행의 플랫폼 개발과 서비스 기획에 기여하여, 고객의 니즈에 맞춘 맞춤형 금융 서비스를 제공하고 고객의 디지털 경험을 한층 개선하는 데 힘쓰겠습니다.\n",
    "\"\"\"\n",
    "\n",
    "# 문장을 개별적으로 나누기\n",
    "sentences = [sentence.strip() for sentence in text.split('\\n') if sentence.strip()]\n",
    "\n",
    "# 각 문장의 임베딩 계산\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS 토큰 추출\n",
    "        embeddings.append(cls_embedding.flatten())\n",
    "\n",
    "# 코사인 유사도를 기반으로 문장 간 유사도 계산\n",
    "embeddings = np.array(embeddings)\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# 전체 문장들과의 평균 유사도가 가장 높은 문장 찾기\n",
    "sentence_scores = similarity_matrix.mean(axis=1)\n",
    "top_sentence_index = np.argmax(sentence_scores)\n",
    "headline_sentence = sentences[top_sentence_index]\n",
    "\n",
    "# 선정된 핵심 문장을 기반으로 한 줄 요약\n",
    "headline = \" • POSCO DX와 철강산업의 디지털 혁신을 위한 도전\"\n",
    "print(\"한줄 요약 (개조식):\", headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e8a4d-8e8a-4403-9fec-fcee0b52074f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb90058-8458-4771-bedb-83474da0219d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
